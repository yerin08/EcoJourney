import json
import os
from typing import Dict, Any

from dotenv import load_dotenv

# -------------------------------
# 1) .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
# -------------------------------
load_dotenv(override=True) # í”„ë¡œì íŠ¸ ë£¨íŠ¸(OpenSourceProject/.env)ì—ì„œ ë¡œë“œ

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # .envì—ì„œ í‚¤ ì½ê¸°
PRIMARY_MODEL = "gemini-2.5-flash"  # ê¸°ë³¸ ëª¨ë¸
FALLBACK_MODELS = [
    "gemini-1.5-flash",    # 1ì°¨ ëŒ€ì²´ ëª¨ë¸ (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥)
    "gemini-1.5-flash-latest",  # 2ì°¨ ëŒ€ì²´ ëª¨ë¸
]

# -------------------------------
# 2) Gemini SDK ë¡œë”©
# -------------------------------
try:
    import google.generativeai as genai
except ImportError:
    genai = None

# -------------------------------
# 3) Gemini ì´ˆê¸°í™”
# -------------------------------
if genai and GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception as e:
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ëŠ” í´ë°±ì„ ì‚¬ìš©í•˜ë„ë¡ ë¹„í™œì„±í™”
        genai = None
else:
    genai = None


# ======================================================================
# 1) Gemini ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  í´ë°±(ê¸°ë³¸ ì‘ë‹µ)
# ======================================================================
def _build_simulated_response(user_data: Dict[str, Any]) -> Dict[str, Any]:
    """Gemini í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ ê¸°ë°˜ JSON ì‘ë‹µ ìƒì„±"""
    carbon_data = user_data.get("category_carbon_data", {}) or {}
    total_carbon_kg = user_data.get("total_carbon_kg", 0.0)

    has_data = bool(carbon_data) and any(v > 0 for v in carbon_data.values())

    # ë°ì´í„°ê°€ ìˆì„ ë•Œ
    if has_data:
        max_category = max(carbon_data, key=carbon_data.get)
        max_value = float(carbon_data[max_category])
        total = float(sum(carbon_data.values())) or 1.0
        max_ratio = (max_value / total) * 100

        # ë‘ ë²ˆì§¸ ì¹´í…Œê³ ë¦¬
        sorted_items = sorted(carbon_data.items(), key=lambda x: x[1], reverse=True)
        second_category, second_value = (None, 0.0)
        if len(sorted_items) >= 2:
            second_category, second_value = sorted_items[1]

        # ì§€êµ¬ ìƒíƒœ ë ˆë²¨(ê°„ë‹¨ ê³„ì‚°)
        if total_carbon_kg <= 2:
            earth_level = "Level 1 - ì•„ì£¼ ìƒì¾Œí•´ìš” ğŸƒ"
        elif total_carbon_kg <= 5:
            earth_level = "Level 2 - ê½¤ ê´œì°®ì€ í•˜ë£¨ì˜ˆìš” ğŸ™‚"
        else:
            earth_level = "Level 3 - ì¡°ê¸ˆ ì§€ì¹œ í•˜ë£¨ì˜ˆìš” ğŸŒ"

        report_title = f"ì˜¤ëŠ˜ í•˜ë£¨ íƒ„ì†Œ ì§„ë‹¨ ê²°ê³¼ ({total_carbon_kg:.2f} kg CO2e)"

        today_result_screen = {
            "usage_summary_text": f"ì˜¤ëŠ˜ íƒ„ì†Œ ì‚¬ìš©ëŸ‰ì€ ì´ {total_carbon_kg:.2f} kg CO2eì˜ˆìš”.",
            "category_ratio_text": (
                f"{max_ratio:.0f}%ê°€ '{max_category}'ì—ì„œ ë°œìƒí–ˆê³ , "
                f"ë‹¤ìŒì€ '{second_category}'ì…ë‹ˆë‹¤." if second_category
                else f"ê±°ì˜ ëŒ€ë¶€ë¶„ì´ '{max_category}'ì—ì„œ ë°œìƒí–ˆì–´ìš”."
            ),
            "money_saving_text": "ì˜¤ëŠ˜ íŒ¨í„´ë§Œ ì¡°ì •í•´ë„ í•œ ë‹¬ ê¸°ì¤€ ìƒí™œë¹„ ì ˆê° ì—¬ì§€ê°€ ìˆì–´ìš”.",
            "earth_status_text": f"ì˜¤ëŠ˜ì˜ ì§€êµ¬ ìƒíƒœëŠ” {earth_level}",
        }

        final_summary = (
            f"ì˜¤ëŠ˜ ì´ ë°°ì¶œëŸ‰ì€ {total_carbon_kg:.2f} kg CO2e. "
            f"'{max_category}' ë¹„ì¤‘ì´ ê°€ì¥ ë†’ê³ , "
            f"'{second_category}'ê°€ ë’¤ë¥¼ ì‡ìŠµë‹ˆë‹¤." if second_category
            else f"ì˜¤ëŠ˜ì€ '{max_category}' í•œ ì˜ì—­ì— ì‚¬ìš©ëŸ‰ì´ ëª°ë¦° íŒ¨í„´ì´ì—ìš”."
        )

        category_chart_text = (
            f"ê·¸ë˜í”„ì—ì„œë„ '{max_category}'ì™€ '{second_category}'ê°€ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤."
            if second_category else
            f"'{max_category}'ê°€ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë³´ë‹¤ ë†’ê²Œ ë‚˜íƒ€ë‚˜ìš”."
        )

        recommendations = [
            {
                "action": f"'{max_category}' ì‚¬ìš©ëŸ‰ 20% ì¤„ì´ê¸°",
                "detail": (
                    f"'{max_category}' ì‚¬ìš©ì´ ë†’ì•˜ë˜ ì´ìœ ë¥¼ ë– ì˜¬ë¦¬ê³ , "
                    "ê°€ì¥ ë°˜ë³µëœ í–‰ë™ 1ê°œë§Œ 20% ì¤„ì—¬ë³´ì„¸ìš”."
                ),
                "impact": f"{max_value * 0.2:.2f} kg CO2e ê°ì¶• ê°€ëŠ¥",
                "reason": f"'{max_category}'ê°€ ì˜¤ëŠ˜ ë°°ì¶œì˜ í•µì‹¬ ìš”ì¸ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            },
            {
                "action": "ë¹„ìŠ·í•œ ìƒí™©ì„ ìœ„í•œ í”Œëœ B ë§Œë“¤ê¸°",
                "detail": (
                    "ë°”ìœ ì‹œê°„ëŒ€ì— ì“°ëŠ” ì´ë™/ì†Œë¹„ íŒ¨í„´ì„ ë– ì˜¬ë¦¬ê³  "
                    "ëŒ€ì²´ í–‰ë™ 1ê°€ì§€ë§Œ ë¯¸ë¦¬ ì •í•´ë‘ì„¸ìš”."
                ),
                "impact": "ë°˜ë³µë ìˆ˜ë¡ ê°ì¶• íš¨ê³¼ê°€ ëˆ„ì ë©ë‹ˆë‹¤.",
                "reason": "ì˜¤ëŠ˜ ë°ì´í„°ê°€ ë°˜ë³µ íŒ¨í„´ì˜ íŒíŠ¸ë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            },
            {
                "action": "íƒ„ì†Œê°€ ë§ì´ ì˜¤ë¥¸ 'ìœ„í—˜ ì‹œê°„ëŒ€' ì¸ì§€í•˜ê¸°",
                "detail": (
                    "íƒ„ì†Œ ì‚¬ìš©ì´ ì¦ê°€í•œ ì‹œê°„ëŒ€ë¥¼ ë– ì˜¬ë¦¬ê³ , "
                    "í•´ë‹¹ ì‹œê°„ëŒ€ì— ì„ íƒì„ í•œ ë²ˆ ë” ì ê²€í•´ë³´ì„¸ìš”."
                ),
                "impact": "ì¶©ë™ ì†Œë¹„Â·ì´ë™ ê°ì†Œ íš¨ê³¼",
                "reason": "ì‹œê°„ëŒ€ ê¸°ë°˜ íŒ¨í„´ íŒŒì•…ì´ í–‰ë™ ì¡°ì ˆì— íš¨ê³¼ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            },
        ]

        simulated = {
            "report_title": report_title,
            "today_result_screen": today_result_screen,
            "final_report_screen": {
                "total_summary_text": final_summary,
                "category_chart_text": category_chart_text,
                "focus_area": max_category,
                "recommendations": recommendations,
                "policy_recommendations": [],
                "closing_message": (
                    f"ì¶”ì²œ ì¤‘ í•œ ê°€ì§€ë§Œ ì‹¤í–‰í•´ë„ '{max_category}' ê°œì„ ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤."
                ),
            },
        }

    # ë°ì´í„° ì—†ì„ ë•Œ
    else:
        simulated = {
            "report_title": "ì˜¤ëŠ˜ì€ ê¸°ë¡ëœ íƒ„ì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”.",
            "today_result_screen": {
                "usage_summary_text": "íƒ„ì†Œ ì‚¬ìš©ëŸ‰ ê¸°ë¡ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.",
                "category_ratio_text": "ì¹´í…Œê³ ë¦¬ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤.",
                "money_saving_text": "ê¸°ë¡ì„ ì‹œì‘í•˜ë©´ ì ˆê° ì§€ì ì„ ë” ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆì–´ìš”.",
                "earth_status_text": "ë‚´ì¼ë¶€í„° í•œ ì¹´í…Œê³ ë¦¬ë§Œ ê¸°ë¡í•´ë´ë„ ì˜ë¯¸ê°€ ìƒê²¨ìš”.",
            },
            "final_report_screen": {
                "total_summary_text": "ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ íŒ¨í„´ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤.",
                "category_chart_text": "ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
                "focus_area": "ê¸°ë¡ ì‹œì‘í•˜ê¸°",
                "recommendations": [
                    {
                        "action": "ë‚´ì¼ ì¹´í…Œê³ ë¦¬ í•˜ë‚˜ë§Œ ê¸°ë¡í•˜ê¸°",
                        "detail": "êµí†µÂ·ìŒì‹ ë“± í•œ ì˜ì—­ë§Œ ìˆ«ìë¡œ ê¸°ë¡í•´ë³´ì„¸ìš”.",
                        "impact": "ê¸°ë¡ì´ ìŒ“ì´ë©´ ì •í™•í•œ ê°ì¶• ì „ëµ ë„ì¶œ ê°€ëŠ¥",
                        "reason": "í˜„ì¬ëŠ” ë¶„ì„ ê°€ëŠ¥í•œ ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
                    }
                ],
                "policy_recommendations": [],
                "closing_message": "ë¶€ë‹´ ì—†ì´ ë‚´ì¼ í•œ ì¹´í…Œê³ ë¦¬ë§Œ ê¸°ë¡í•´ë´ìš”.",
            },
        }

    return simulated


# ======================================================================
# 2) Gemini ëª¨ë¸ í˜¸ì¶œ í—¬í¼ í•¨ìˆ˜
# ======================================================================
def _call_gemini_model(model_name: str, prompt: str) -> str:
    """íŠ¹ì • Gemini ëª¨ë¸ë¡œ API í˜¸ì¶œ"""
    model = genai.GenerativeModel(model_name)
    response = model.generate_content(prompt)
    
    # ì‘ë‹µ í…ìŠ¤íŠ¸ ì•ˆì „ ì¶”ì¶œ (candidates/parts ìš°ì„ )
    raw_text = ""
    try:
        if hasattr(response, "candidates") and response.candidates:
            for cand in response.candidates:
                parts = getattr(cand, "content", None) or getattr(cand, "parts", None)
                if parts and hasattr(parts, "__iter__"):
                    texts = [
                        getattr(p, "text", None) or str(getattr(p, "data", "")) or ""
                        for p in parts
                        if p is not None
                    ]
                    joined = "\n".join([t for t in texts if t]).strip()
                    if joined:
                        raw_text = joined
                        break
        if not raw_text:
            raw_text = (getattr(response, "text", None) or "").strip()
    except Exception:
        raw_text = (getattr(response, "text", None) or "").strip()

    if not raw_text:
        raise ValueError("LLM ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    return raw_text

# ======================================================================
# 3) Gemini í˜¸ì¶œ + JSON íŒŒì‹± + ë‹¤ë¥¸ ëª¨ë¸ í´ë°±
# ======================================================================
def call_llm_api(prompt: str, user_data: Dict[str, Any]) -> str:
    """Gemini ê¸°ë³¸ ëª¨ë¸ í˜¸ì¶œ â†’ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ Gemini ëª¨ë¸ë“¤ ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ í´ë°± JSON ë°˜í™˜"""
    if not genai or not GEMINI_API_KEY:
        simulated = _build_simulated_response(user_data)
        return json.dumps(simulated, ensure_ascii=False, indent=4)

    # ì‹œë„í•  ëª¨ë¸ ëª©ë¡ (ê¸°ë³¸ ëª¨ë¸ + ëŒ€ì²´ ëª¨ë¸ë“¤)
    models_to_try = [PRIMARY_MODEL] + FALLBACK_MODELS
    
    for model_name in models_to_try:
        try:
            raw_text = _call_gemini_model(model_name, prompt)
            
            # ì½”ë“œë¸”ë¡(```) ì œê±°
            if raw_text.startswith("```"):
                lines = raw_text.splitlines()
                if len(lines) >= 2 and lines[0].startswith("```") and lines[-1].startswith("```"):
                    lines = lines[1:-1]
                if lines and lines[0].strip().lower() == "json":
                    lines = lines[1:]
                raw_text = "\n".join(lines).strip()

            # JSON íŒŒì‹±
            parsed = json.loads(raw_text)
            return json.dumps(parsed, ensure_ascii=False, indent=4)

        except Exception as e:
            error_str = str(e)
            # 429 ì—ëŸ¬(í• ë‹¹ëŸ‰ ì´ˆê³¼) ë˜ëŠ” quota ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° ë‹¤ìŒ ëª¨ë¸ë¡œ ì „í™˜
            if "429" in error_str or "quota" in error_str.lower() or "Quota exceeded" in error_str:
                pass
            # ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° (404 ì—ëŸ¬ í¬í•¨)
            elif "not found" in error_str.lower() or "invalid" in error_str.lower() or "does not exist" in error_str.lower() or "not available" in error_str.lower() or "404" in error_str:
                pass
            # API í‚¤ ê´€ë ¨ ì—ëŸ¬
            elif "api key" in error_str.lower() or "authentication" in error_str.lower() or "unauthorized" in error_str.lower() or "403" in error_str:
                # API í‚¤ ë¬¸ì œëŠ” ëª¨ë“  ëª¨ë¸ì—ì„œ ë™ì¼í•˜ë¯€ë¡œ ì¦‰ì‹œ í´ë°±
                break
            else:
                pass
            
            # ë§ˆì§€ë§‰ ëª¨ë¸ì´ ì•„ë‹ˆë©´ ê³„ì† ì‹œë„
            if model_name != models_to_try[-1]:
                continue
    
    # ëª¨ë“  Gemini ëª¨ë¸ ì‹¤íŒ¨ ì‹œ í´ë°±
    simulated = _build_simulated_response(user_data)
    return json.dumps(simulated, ensure_ascii=False, indent=4)


# ======================================================================
# 3) ì™¸ë¶€ í˜¸ì¶œìš© ë©”ì¸ í•¨ìˆ˜
# ======================================================================
def get_coaching_feedback(user_data: Dict[str, Any]) -> str:
    """coaching_apiì—ì„œ í˜¸ì¶œí•˜ëŠ” LLM í”¼ë“œë°± ìƒì„± ì§„ì…ì """
    from ecojourney.config.coaching_rules import COACHING_KNOWLEDGE_RULE

    prompt = create_coaching_prompt(user_data, COACHING_KNOWLEDGE_RULE)
    return call_llm_api(prompt, user_data)


# ======================================================================
# 4) í”„ë¡¬í”„íŠ¸ ìƒì„±
# ======================================================================
def create_coaching_prompt(
    user_data: Dict[str, Any],
    knowledge_rule: Dict[str, Any],
) -> str:
    """ì˜¤ëŠ˜ í•˜ë£¨ ë°ì´í„° ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    carbon_data = (
        user_data.get("category_carbon_data")
        or user_data.get("category_activity_data")
        or {}
    )

    total_carbon_kg = user_data.get("total_carbon_kg")
    if total_carbon_kg is None:
        try:
            total_carbon_kg = float(sum(carbon_data.values())) if carbon_data else 0.0
        except Exception:
            total_carbon_kg = 0.0
    else:
        try:
            total_carbon_kg = float(total_carbon_kg)
        except Exception:
            total_carbon_kg = 0.0

    category_summary = (
        "\n".join([f"- {k}: {float(v):.2f} kg CO2e" for k, v in carbon_data.items()])
        if carbon_data else "- ìƒì„¸ ë°ì´í„° ì—†ìŒ"
    )

    data_summary = (
        "## [ì‚¬ìš©ì ì˜¤ëŠ˜ í•˜ë£¨ íƒ„ì†Œ ë°ì´í„°]\n"
        f"- ì´ ë°°ì¶œëŸ‰: {total_carbon_kg:.2f} kg CO2e\n"
        "## [ì¹´í…Œê³ ë¦¬ë³„ ë°°ì¶œëŸ‰]\n"
        f"{category_summary}\n"
    )

    system_instruction = knowledge_rule["system_instruction"]
    coaching_principles = "\n\n".join(
        [f"- {p}" for p in knowledge_rule.get("coaching_principles", [])]
    )
    json_schema = json.dumps(
        knowledge_rule["json_schema"],
        ensure_ascii=False,
        indent=2,
    )

    policy_candidates = user_data.get("policy_candidates") or []
    policy_text = ""
    if isinstance(policy_candidates, list) and policy_candidates:
        lines = []
        for p in policy_candidates:
            if not isinstance(p, dict):
                continue
            name = p.get("name")
            reason = p.get("reason")
            url = p.get("url")
            if name or reason or url:
                line = f"- ì´ë¦„: {name or ''} | ì„¤ëª…: {reason or ''} | ë§í¬: {url or ''}"
                lines.append(line)
        if lines:
            policy_text = "\n".join(lines)

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
{system_instruction}

[ë°ì´í„° ë¶„ì„ ì›ì¹™]
{coaching_principles}

[ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°]
{data_summary}

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ëŠ” **í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
ì„¤ëª…ë¬¸Â·ì½”ë“œë¸”ë¡(```) ê¸ˆì§€.

JSON ìŠ¤í‚¤ë§ˆ:
{json_schema}

[ì •ì±…/í˜œíƒ í›„ë³´ ëª©ë¡]
ì•„ë˜ ëª©ë¡ ì•ˆì—ì„œë§Œ ì •ì±…/í˜œíƒì„ ì„ íƒí•´ policy_recommendationsë¥¼ ì‘ì„±í•˜ì„¸ìš”.
ëª©ë¡ì— ì—†ëŠ” ì •ì±… ì´ë¦„ì„ ìƒˆë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
{policy_text or '- ì œê³µëœ ì •ì±… í›„ë³´ ì—†ìŒ'}

[ì¶”ê°€ ì¡°ê±´]
- í•œêµ­ì–´ë¡œ ì‘ì„±.
- ì˜¤ëŠ˜ í•˜ë£¨ ë°ì´í„°ë§Œ ê¸°ì¤€.
- í–‰ë™ ì¶”ì²œ 3~5ê°œ í¬í•¨.
- ì •ì±…/í˜œíƒ ì¶”ì²œì€ 1~2ê°œ(ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´).
"""

    return prompt.strip()
